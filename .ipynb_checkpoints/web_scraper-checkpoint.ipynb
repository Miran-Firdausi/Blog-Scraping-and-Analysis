{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03b9390-be16-4df6-8dc1-32d7bb9be206",
   "metadata": {},
   "source": [
    "# Web Scraping and Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e25674-1b64-4faa-a320-bc0fea7bf641",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19472d93-3170-49d9-940d-88c9ee7ae079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\miran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from helper import load_words, count_syllables\n",
    "import string\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed02d4-b765-4916-8e04-8a2a5b739623",
   "metadata": {},
   "source": [
    "### Fetching URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff323ce-c579-4430-b33a-db5c3f3491fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/'\n",
    "page = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb2b187-a6ee-452a-810e-0077e96bee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the HTML content\n",
    "html = page.text\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3266011-dada-4c03-8d39-540e563d39d3",
   "metadata": {},
   "source": [
    "### Extracting Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1336a5fb-9fbb-4486-bbad-8a62744f858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title of the article\n",
    "title_element = soup.find('h1', {'class': 'entry-title'})\n",
    "if title_element is None:\n",
    "    title_element = soup.find('h1', {'class': 'tdb-title-text'})\n",
    "if title_element:\n",
    "    title = title_element.text.strip()\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b51e12ff-7277-480c-9aa1-acf13e685718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the main body content of the article\n",
    "body_element = soup.find('div', {'class': 'td-post-content tagdiv-type'})\n",
    "if body_element is None:\n",
    "    body_element = soup.find('div', {'class': 'td_block_wrap tdb_single_content tdi_130 td-pb-border-top td_block_template_1 td-post-content tagdiv-type'})\n",
    "if body_element:\n",
    "    body = body_element.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a670eb-f3c4-4cbe-aa65-ca828c490b36",
   "metadata": {},
   "source": [
    "### Save article to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a0a5f-c3c2-4922-8fe2-38a4b4c35f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_dir = 'ArticleText'\n",
    "os.makedirs(article_dir, exist_ok=True)\n",
    "article_file = os.path.join(article_dir, f\"{url_id}.txt\")\n",
    "\n",
    "# Save article to text file\n",
    "with open(article_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(body)\n",
    "print(f\"Article {url_id} scraped and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cdf797a4-1fed-4eb4-9eac-0e9634a720df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stop words from list of files\n",
    "stop_word_files = ['stopWords/stopWords_Auditor.txt', 'stopWords/stopWords_currencies.txt', 'stopWords/StopWords_DatesandNumbers.txt', 'stopWords/StopWords_GenericLong.txt' , 'StopWords/stopwords_Generic.txt', 'stopWords/StopWords_Geographic.txt', 'StopWords/stopwords_Names.txt']\n",
    "stop_words = load_words(stop_word_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92cea3a4-7ab1-4b34-85b0-d46b93cad58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive and negative word list\n",
    "positive_words = load_words(['MasterDictionary/positive-words.txt'])\n",
    "negative_words = load_words(['MasterDictionary/negative-words.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c25f71e-53be-46a2-9289-15998d39d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into sentences and words\n",
    "sentences = sent_tokenize(body)\n",
    "tokens = word_tokenize(body)\n",
    "\n",
    "# Filter out stop words and punctuation\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8876c5-de32-4a81-bc76-c6a23b2b683a",
   "metadata": {},
   "source": [
    "### 1. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ef87eb2-023b-4156-87d5-45966c8f8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score = sum(1 for word in filtered_tokens if word in positive_words)\n",
    "negative_score = sum(-1 for word in filtered_tokens if word in negative_words)\n",
    "negative_score *= -1\n",
    "\n",
    "# Calculate polarity and subjectivity scores\n",
    "polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "subjectivity_score = (positive_score + negative_score) / (len(filtered_tokens) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5dfa12d-738f-4df2-a8ba-7f63c2b57006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 54\n",
      "Negative Score: 6\n",
      "Polarity Score: 0.7999999866666669\n",
      "Subjectivity Score: 0.07109004730913501\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive Score:\", positive_score)\n",
    "print(\"Negative Score:\", negative_score)\n",
    "print(\"Polarity Score:\", polarity_score)\n",
    "print(\"Subjectivity Score:\", subjectivity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0409eea-10dc-41fe-a663-71b4c700da23",
   "metadata": {},
   "source": [
    "### 2. Readability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6de5d73d-6c90-4caf-9fe6-97adcb013af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentence_length = len(tokens) / len(sentences)\n",
    "\n",
    "complex_words = [word for word in filtered_tokens if count_syllables(word) > 2]\n",
    "percent_complex_words = len(complex_words) / len(filtered_tokens)\n",
    "\n",
    "fog_index = 0.4 * (avg_sentence_length + percent_complex_words * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54fe55cb-4008-4d0b-b0f8-3ae8d24298ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length: 20.526315789473685\n",
      "Percentage of Complex Words: 49.28909952606635 %\n",
      "Fog Index: 27.926166126216017\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Sentence Length:\", avg_sentence_length)\n",
    "print(\"Percentage of Complex Words:\", percent_complex_words * 100, \"%\")\n",
    "print(\"Fog Index:\", fog_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a29341-15a9-4949-b86c-d06eed5530cf",
   "metadata": {},
   "source": [
    "### 3. Average Number of Words Per Sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98cc31d4-23e6-4d92-ba88-bc66ed09cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average No. Of Words Per Sentence: 20.526315789473685\n"
     ]
    }
   ],
   "source": [
    "avg_words_per_sentence = len(tokens) / len(sentences)\n",
    "\n",
    "print(\"Average No. Of Words Per Sentence:\", avg_words_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f62e6-d7c9-4156-9fb0-420567367897",
   "metadata": {},
   "source": [
    "### 4. Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ef9494f-b76d-4d1c-bfd4-75bc1fe49038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Word Count: 416\n"
     ]
    }
   ],
   "source": [
    "complex_word_count = len(complex_words)\n",
    "\n",
    "print(\"Complex Word Count:\", complex_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e6aab-c2ae-4aa0-b7fa-ea9a29d57714",
   "metadata": {},
   "source": [
    "### 5. Word Count Using nltk Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10b1de60-c13e-46a6-b0f1-ec863f62a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 991\n"
     ]
    }
   ],
   "source": [
    "nltk_stop_words = set(stopwords.words('english'))\n",
    "nltk_word_count = sum(1 for w in tokens if not w.lower() in nltk_stop_words and w not in string.punctuation)\n",
    "\n",
    "print(\"Word count:\", nltk_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e054a-0d12-4f22-926b-bc41b9085ba8",
   "metadata": {},
   "source": [
    "### 6. Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f8ca820-57b9-4066-8235-abb5e9497c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable Count Per Word: 2.134207870837538\n"
     ]
    }
   ],
   "source": [
    "total_syllables = sum(count_syllables(word) for word in filtered_tokens)\n",
    "syllable_per_word = total_syllables / nltk_word_count\n",
    "\n",
    "print(\"Syllable Count Per Word:\", syllable_per_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ecdb6-1a4d-4b38-9645-13bbc7f0f458",
   "metadata": {},
   "source": [
    "### 7. Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5080ac6c-b7a0-498e-aefc-1c588ab47184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personal Pronoun Count: 71\n"
     ]
    }
   ],
   "source": [
    "personal_pronouns = ['i', 'me', 'we', 'us', 'you', 'he', 'him', 'she', 'her', 'it', 'they', 'them']\n",
    "\n",
    "# Reg ex used\n",
    "# \\b -> boundary anchor, [\\w.] -> any word character (letters, digits, underscores) or a period (.))\n",
    "pronoun_count = sum(1 for word in re.findall(r'\\b[\\w.]+\\b', body) if word.lower() in personal_pronouns and word not in ['US', 'U.S.', 'U.S'])\n",
    "print(\"Personal Pronoun Count:\", pronoun_count) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9919d1-0f3f-498d-b02c-b08b6743dd2c",
   "metadata": {},
   "source": [
    "### 8. Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4ce1362-a10f-49fd-96e5-7dc6f758cdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.841538461538462"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_characters = sum(len(word) for word in tokens) \n",
    "avg_word_length = sum_of_characters / len(tokens)\n",
    "avg_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ec067-0508-45a7-b30c-9586edf1a34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
